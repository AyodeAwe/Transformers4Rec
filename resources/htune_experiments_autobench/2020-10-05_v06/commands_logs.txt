Starting a small machine to run AutoBench


ngc batch run --name "transf4rec-autobench-htune" --preempt RUNONCE --ace nv-us-west-2 --instance dgx1v.16g.1.norm --commandline "apt update; apt-get install screen -y; pip install -r requirements.txt --quiet; echo "export PATH=\"\$PATH:/wksp/ngc/\"" >> ~/.bash_profile && source ~/.bash_profile && mkdir/root/.ngc ; cp /wksp/ngc/config /root/.ngc/config ; git pull origin experimentation & date & jupyter lab --ip=0.0.0.0 --allow-root --no-browser --NotebookApp.token='' --notebook-dir=/ --NotebookApp.allow_origin='*' & date; sleep 168h" --total-runtime 168h --result /results --image "nvidian/prj-recsys/transf4rec_exp:0.1.0" --org nvidian --team prj-recsys --port 8888 --port 8887 --workspace gmoreira-wksp:/wksp:RW


Commands in the machine:
echo "export PATH=\"\$PATH:/wksp/ngc/\"" >> ~/.bash_profile && source ~/.bash_profile
mkdir/root/.ngc ; cp /wksp/ngc/config /root/.ngc/config


Last Job id: 1500072


---------------------------------------

cd /wksp/autobench


#Hypertuning job - GPT2
screen -S gpt2

python main.py --htune_study_name htune-v06-1-gpt2 --concurrent_jobs 5 --htune_num_trials 100 --verbose --htune_log_dir "/results/gpt2/htune_log" "/workspace/recsys/transformers4recsys/resources/htune_experiments_autobench/2020-10-05_v06/gpt2/tranf4rec-htune-v06-gpt2.yaml"


[then, ctrl + A + D: make me outside of the screen session]



---------------------------------------


#Hypertuning job - GRU

screen -S gru

python main.py --htune_study_name htune-v06.1-gru --concurrent_jobs 5 --htune_num_trials 100 --verbose --htune_log_dir "/results/gru/htune_log" "/workspace/recsys/transformers4recsys/resources/htune_experiments_autobench/2020-10-05_v06/gru/tranf4rec-htune-v06-gru.yaml"

[then, ctrl + A + D: make me outside of the screen session]




---------------------------------------------------------------

Running this job manually because of its high accuracy before crashing (happy-lake-1075)


ngc batch run --name "tranf4rec-htune-v06-gpt2" --preempt RUNONCE --ace nv-us-west-2 --instance dgx1v.32g.2.norm --commandline "nvidia-smi && wandb login 76eea90114bb1cdcbafe151b262e4a5d4ff60f12 && date && git pull origin experimentation && date && bash script/run_transformer_v2.bash htune-v06-gpt2 full_noneg session_cooccurrence --start_date 2019-10-01 --end_date 2019-10-15 --model_type gpt2 --loss_type cross_entropy --per_device_eval_batch_size 128 --similarity_type concat_mlp --tf_out_activation tanh --all_rescale_factor 1.0 --neg_rescale_factor 0.0 --inp_merge mlp --hidden_act gelu_new --learning_rate_warmup_steps 0 --learning_rate_num_cosine_cycles 4.0 --dataloader_drop_last --compute_metrics_each_n_steps 50 --max_seq_len 20 --num_train_epochs 7 --per_device_train_batch_size 128 --learning_rate 0.0028003389578467436 --learning_rate_schedule constant_with_warmup --dropout 0.1 --weight_decay 2.6170162662253176e-05 --d_model 256 --n_layer 2 --n_head 2 && date" --result /results --image "nvidian/prj-recsys/transf4rec_exp:0.1.0" --org nvidian --team prj-recsys --datasetid 66609:/data


Job Information
    Id: 1502547

cosmic-deluge-1136
 

------------------------------------------------

