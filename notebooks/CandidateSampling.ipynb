{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import itertools\n",
    "from itertools import permutations \n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "from copy import deepcopy\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PARQUET_PATH = \"/home/gmoreira/dataset/ecommerce_preproc_2019-*/ecommerce_preproc.parquet/session_start_date=*\"\n",
    "#OUTPUT_NEG_SAMPLES_PARQUET_PATH = \"/home/gmoreira/dataset/neg_samples.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_N_SESSIONS_PER_DAY = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIFORM_SAMPLING = 'uniform'\n",
    "RECENCY_SAMPLING = 'recency'\n",
    "RECENT_POPULARITY_SAMPLING = 'popularity'\n",
    "COOCURRENCE_SAMPLING = 'cooccurrence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEGATIVE_SAMPLING_STRATEGY = COOCURRENCE_SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000\n",
    "BATCHES_TO_UPDATE_ITEM_STATS = 3\n",
    "BATCHES_TO_APPEND_ROWS_WITH_NEG_SAMPLES = 5\n",
    "ITEM_STATS_KEEP_LAST_N_DAYS = 1.0\n",
    "SEQUENCE_LENGTH = 20\n",
    "NUM_NEG_SAMPLES = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-01',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-02',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-03',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-04',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-05',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-06',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-07',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-08',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-09',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-10',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-11',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-12',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-13',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-14',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-15',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-16',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-17',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-18',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-19',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-20',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-21',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-22',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-23',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-24',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-25',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-26',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-27',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-28',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-29',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-30',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-31',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-01',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-02',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-03',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-04',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-05',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-06',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-07',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-08',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-09',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-10',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-11',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-12',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-13',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-14',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-15',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-16',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-17',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-18',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-19',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-20',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-21',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-22',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-23',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-24',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-25',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-26',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-27',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-28',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-29',\n",
       " '/home/gmoreira/dataset/ecommerce_preproc_2019-11/ecommerce_preproc.parquet/session_start_date=2019-11-30']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_parquet_files = sorted(glob.glob(INPUT_PARQUET_PATH+'*'))\n",
    "input_parquet_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_path_parquet_neg_samples(input_parquet_filename):\n",
    "    return input_parquet_filename \\\n",
    "        .replace('ecommerce_preproc.parquet', 'ecommerce_preproc_neg_samples_{}_strategy_{}.parquet' \\\n",
    "                     .format(NUM_NEG_SAMPLES, NEGATIVE_SAMPLING_STRATEGY)) + '.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def get_files(data_paths):\n",
    "    paths = [['file://' + p for p in glob.glob(path + \"/*.parquet\")] for path in data_paths]\n",
    "    return list(itertools.chain.from_iterable(paths))\n",
    "input_parquet_files = get_files([INPUT_PARQUET_PATH])\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Works but cannot be used now because the preprocessed sessions are not sorted by timestamp\n",
    "def read_parquet_generator(filenames, batch_size=128):\n",
    "    for filename in filenames:\n",
    "        for batch in pq.read_table(filename).to_batches(batch_size):\n",
    "            yield batch.to_pandas()\n",
    "            \n",
    "parquet_reader = read_parquet_generator([INPUT_PARQUET_PATH], batch_size=BATCH_SIZE)            \n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe_into_chuncks_generator(df, chunk_size): \n",
    "    number_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(number_chunks):\n",
    "        yield df[i*chunk_size:(i+1)*chunk_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_update_session_items_metadata(row):\n",
    "    #Uses the session start as the event timestamp (as the sess_etime_seq might sometimes be many days before because of outlier sessions with more than 120 min duration (< 1%))\n",
    "    etime = row['session_start_ts']\n",
    "    #For each session\n",
    "    for pid, csid, ccid, bid, price, relative_price, prod_recency in zip(\n",
    "                                                        #row['sess_etime_seq'],\n",
    "                                                        row['sess_pid_seq'], \n",
    "                                                        row['sess_csid_seq'],\n",
    "                                                        row['sess_ccid_seq'],\n",
    "                                                        row['sess_bid_seq'],\n",
    "                                                        row['sess_price_seq'],\n",
    "                                                        row['sess_relative_price_to_avg_category_seq'],\n",
    "                                                        row['sess_product_recency_seq']):\n",
    "\n",
    "        #If this item was not processed before\n",
    "        if pid != 0:\n",
    "            if pid in items_df.index:\n",
    "                curr_row = items_df.loc[pid]\n",
    "\n",
    "                first_ts = curr_row['first_ts']\n",
    "                last_ts = curr_row['last_ts']\n",
    "                if etime > last_ts:\n",
    "                    last_ts = etime\n",
    "            else:\n",
    "                first_ts = etime\n",
    "                last_ts = etime\n",
    "\n",
    "            #Including or updating the item metadata\n",
    "            items_df.loc[pid] = pd.Series({'csid': csid,\n",
    "                                           'ccid': ccid,\n",
    "                                           'bid': bid,\n",
    "                                           'price': price,\n",
    "                                           'relative_price_to_avg_category': relative_price,\n",
    "                                           'product_recency': prod_recency,\n",
    "                                           'first_ts': first_ts,\n",
    "                                           'last_ts': last_ts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_cooccurrences_log_list = []\n",
    "\n",
    "def append_session_coocurrences_log(row):\n",
    "    global session_cooccurrences_log_list\n",
    "    min_ts = min([t for t in row['sess_etime_seq'] if t != 0])\n",
    "    valid_pids = list(set(list([p for p in row['sess_pid_seq'] if p != 0])))\n",
    "    \n",
    "    if len(valid_pids) > 1:\n",
    "        items_permutations = permutations(valid_pids, 2)        \n",
    "        new_coo_df = pd.DataFrame(items_permutations, columns=['pid_a', 'pid_b'])\n",
    "        new_coo_df['ts'] = min_ts\n",
    "        #This flag is used for counting unique values from this table to compute popularity\n",
    "        new_coo_df['count_flag'] = ([1] + [0]*(len(valid_pids)-2))*len(valid_pids)\n",
    "        \n",
    "        session_cooccurrences_log_list.append(new_coo_df)\n",
    "\n",
    "def concat_sessions_coocurrences_log():\n",
    "    global items_coocurrence_df, session_cooccurrences_log_list\n",
    "    items_coocurrence_df = pd.concat([items_coocurrence_df] + session_cooccurrences_log_list)\n",
    "    session_cooccurrences_log_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_old_interactions(keep_last_n_days):\n",
    "    global items_coocurrence_df\n",
    "    last_ts = items_coocurrence_df['ts'].max()\n",
    "    keep_last_n_secs = keep_last_n_days * 24 * 60 * 60\n",
    "    items_coocurrence_df = items_coocurrence_df[items_coocurrence_df['ts'] >= (last_ts - keep_last_n_secs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_items_temporal_relevance_decay():    \n",
    "    global items_temporal_relev_df\n",
    "    max_reference_ts = items_df['first_ts'].max()\n",
    "    prods_days_age = (max_reference_ts - items_df['first_ts']) / (60 * 60 * 24)\n",
    "\n",
    "    time_relev_by_item_series = prod_relevance_decay(prods_days_age)\n",
    "    items_temporal_relev_df = time_relev_by_item_series / time_relev_by_item_series.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_items_coocurrences_counts():\n",
    "    global items_coocurence_counts_df\n",
    "    items_coocurence_counts_df = items_coocurrence_df.groupby(['pid_a','pid_b']).size().to_frame('count') \\\n",
    "                                    .reset_index(level=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_items_recent_popularity():\n",
    "    global items_recent_pop_df\n",
    "    items_recent_pop_df = items_coocurrence_df[items_coocurrence_df['count_flag'] == True] \\\n",
    "            .groupby(['pid_a']).size().to_frame('count')\n",
    "    items_recent_pop_df['prob'] = items_recent_pop_df['count'] / items_recent_pop_df['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (83% of relevance in one quarter, 70% in one semester, 50% in one year and 23% in two years)\n",
    "DAYS_DECAY_FACTOR = 0.002\n",
    "\n",
    "def prod_relevance_decay(days_age):\n",
    "    return np.exp(-days_age*DAYS_DECAY_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0\n",
      "30 0.9417645335842487\n",
      "60 0.8869204367171575\n",
      "90 0.835270211411272\n",
      "120 0.7866278610665535\n",
      "150 0.7408182206817179\n",
      "180 0.697676326071031\n",
      "210 0.6570468198150567\n",
      "240 0.6187833918061408\n",
      "270 0.5827482523739896\n",
      "300 0.5488116360940264\n",
      "330 0.5168513344916992\n",
      "360 0.4867522559599717\n",
      "390 0.4584060113052235\n",
      "420 0.43171052342907973\n",
      "450 0.4065696597405991\n",
      "480 0.38289288597511206\n",
      "510 0.3605949401730783\n",
      "540 0.3395955256449391\n",
      "570 0.31981902181630384\n",
      "600 0.30119421191220214\n",
      "630 0.2836540264997704\n",
      "660 0.26713530196585034\n",
      "690 0.25157855305975646\n",
      "720 0.23692775868212176\n"
     ]
    }
   ],
   "source": [
    "# (83% of relevance in one quarter, 70% in one semester, 50% in one year and 23% in two years)\n",
    "DAYS_DECAY_FACTOR = 0.002\n",
    "# Simulating 2 year of decay on relevance of a product \n",
    "for i in np.arange(0,365*2,30):    \n",
    "    print(i, prod_relevance_decay(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = None\n",
    "items_coocurrence_df = None\n",
    "items_coocurence_counts_df = None\n",
    "items_recent_pop_df = None\n",
    "items_temporal_relev_df = None\n",
    "\n",
    "def reset_item_logs_and_statistics():\n",
    "    global items_df, items_coocurrence_df, items_coocurence_counts_df, items_recent_pop_df, items_temporal_relev_df\n",
    "    \n",
    "    items_df = pd.DataFrame(columns={'pid': np.int64,\n",
    "                                 'csid': np.int32,\n",
    "                                 'ccid': np.int32,\n",
    "                                 'bid': np.int32,\n",
    "                                 'price': np.float,\n",
    "                                 'relative_price_to_avg_category': np.float,\n",
    "                                 'product_recency': np.float,\n",
    "                                 'first_ts': np.int,\n",
    "                                 'last_ts': np.int\n",
    "                                }).set_index('pid')\n",
    "    \n",
    "    items_coocurrence_df = pd.DataFrame(columns={'pid_a': np.int64, \n",
    "                                                 'pid_b': np.int64, \n",
    "                                                 'ts': np.int32, \n",
    "                                                 'count_flag': np.int16})\n",
    "    \n",
    "    items_coocurence_counts_df = None\n",
    "    items_recent_pop_df = None\n",
    "    items_temporal_relev_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uniform_sampling_item_ids(n_samples):\n",
    "    return np.random.choice(items_df.index, min(n_samples, len(items_df)), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_popularity_sampling_item_ids(n_samples):\n",
    "    return np.random.choice(items_recent_pop_df.index, min(n_samples, len(items_recent_pop_df)), replace=False, \n",
    "                            p=items_recent_pop_df['prob']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coocurrence_sampling_item_ids(pid, n_samples):\n",
    "    samples = []\n",
    "    if pid in items_coocurence_counts_df.index:\n",
    "        coocurrent_df = items_coocurence_counts_df.loc[pid]\n",
    "        #Dealing with cases when there is only one co-occurrent item (loc() returns a Series)\n",
    "        if type(coocurrent_df) is pd.Series:\n",
    "            coocurrent_df = coocurrent_df.to_frame().T\n",
    "        coocurrent_df['probs'] = coocurrent_df['count'] / coocurrent_df['count'].sum()\n",
    "        samples = np.random.choice(coocurrent_df['pid_b'], min(n_samples, len(coocurrent_df)), replace=False, \n",
    "                                   p=coocurrent_df['probs']).tolist()\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recency_sampling_item_ids(n_samples):\n",
    "    samples = np.random.choice(items_temporal_relev_df.index, min(n_samples, len(items_temporal_relev_df)), replace=False, \n",
    "                               p=items_temporal_relev_df.values).tolist()\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_samples_item_ids(pid, n_samples, strategy, ignore_list=None):\n",
    "    #To ensure that after removing sessions from the current session we have the required number of samples\n",
    "    SAMPLES_MULITPLIER = 2\n",
    "    if strategy == UNIFORM_SAMPLING:\n",
    "        samples = get_uniform_sampling_item_ids(n_samples*SAMPLES_MULITPLIER)\n",
    "    elif strategy == RECENCY_SAMPLING:\n",
    "        samples = get_recency_sampling_item_ids(n_samples*SAMPLES_MULITPLIER)\n",
    "    elif strategy == RECENT_POPULARITY_SAMPLING:\n",
    "        samples = get_popularity_sampling_item_ids(n_samples*SAMPLES_MULITPLIER)    \n",
    "    elif strategy == COOCURRENCE_SAMPLING:\n",
    "        samples = get_coocurrence_sampling_item_ids(pid, n_samples*SAMPLES_MULITPLIER)\n",
    "    \n",
    "        #Completing the list of samples based on global popularity\n",
    "        if len(samples) < n_samples:\n",
    "            samples += get_popularity_sampling_item_ids(n_samples - len(samples))\n",
    "    else:\n",
    "        raise Exception('Not a valid strategy. Should be: (uniform|recency|popularity|cooccurrence)')\n",
    "        \n",
    "    #Removing repeated entries\n",
    "    samples = list(set(samples))\n",
    "    #Removing samples from the ignore list\n",
    "    if ignore_list is not None:\n",
    "        samples = list([i for i in samples if i not in ignore_list])\n",
    "\n",
    "    return samples[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_candidate_samples_item_ids(63246, 10, strategy=COOCURRENCE_SAMPLING, ignore_list=[2010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_for_item_ids(pids):\n",
    "    return items_df.loc[pids][['csid', 'ccid', 'bid', 'price', 'relative_price_to_avg_category', 'product_recency']] \\\n",
    "    .to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "##%%time\n",
    "#l= np.random.choice(items_df.index, 50)\n",
    "#l= np.ones(50, dtype='int')*10\n",
    "#l = [10] * 50\n",
    "#l = [33284, 6, 21, 2588, 23069, 1570, 8230, 552, 50, 4152, 55864, 24636, 113213, 65601, 9283, 1097, 1104, 90, 2651, 607, 13920, 7785, 619, 8821, 9337, 4221, 8330, 7307, 8848, 19089, 112784, 2197, 15002, 3234, 3252, 1207, 2745, 40128, 30918, 4299, 61646, 23247, 213, 6871, 8921, 15582, 6367, 15077, 8935, 3820, 1266, 1790, 256, 258, 3844, 1808, 14109, 1311, 8481, 3362, 1318, 2348, 301, 29996, 19245, 1331, 3891, 10553, 830, 1855, 1867, 3415, 2933, 8571, 21371, 390, 903, 1425, 404, 5527, 1958, 23477, 6071, 59321, 7100, 4545, 1479, 28628, 10200, 16857, 3544, 479, 480, 6628, 35812, 2032, 3059, 28153, 2046]\n",
    "#for i in range(100):\n",
    "#    for j in range(10):\n",
    "#        x = get_features_for_item_ids(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padarray(A, size):\n",
    "    if len(A) > size:\n",
    "        A = A[:size]\n",
    "    t = size - len(A)\n",
    "    return np.pad(A, pad_width=(0, t), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padarray([1,2,3], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_neg_samples(session_pids, user_past_pids, n_samples, strategy):\n",
    "    neg_samples_dict = defaultdict(list)\n",
    "    \n",
    "    #Ignores session items and also recently interacted items\n",
    "    ignore_ids = set(np.hstack([session_pids, user_past_pids]))\n",
    "    \n",
    "    for pid in session_pids:\n",
    "        if pid != 0:\n",
    "            #Sampling item idds\n",
    "            neg_item_ids = get_candidate_samples_item_ids(pid, n_samples, \n",
    "                                                          ignore_list=ignore_ids,\n",
    "                                                         strategy=strategy\n",
    "                                                         )      \n",
    "            #Retrieving item features\n",
    "            neg_item_features_dict = get_features_for_item_ids(neg_item_ids)\n",
    "\n",
    "            \n",
    "            pids_padded = padarray(neg_item_ids, n_samples).astype(int)\n",
    "            neg_samples_dict['sess_neg_pids'].append(pids_padded)\n",
    "            \n",
    "            for k, v in neg_item_features_dict.items():\n",
    "                values = padarray(v, n_samples)\n",
    "                values = values.astype(int) if k in ['csid', 'ccid', 'bid'] else values.astype(float)\n",
    "                neg_samples_dict['sess_neg_{}'.format(k)].append(values)\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            #Creating padding neg samples for each padding interactions\n",
    "            missing_padding_neg_samples = len(session_pids) - len(neg_samples_dict['sess_neg_pids'])                        \n",
    "            for k in neg_samples_dict:\n",
    "                neg_samples = neg_samples_dict[k]\n",
    "                neg_samples_zeros = np.zeros_like(neg_samples[0])\n",
    "                for p in range(missing_padding_neg_samples):\n",
    "                    #Copying shape and dtype from the neg samples of the first interaction\n",
    "                    neg_samples.append(neg_samples_zeros)\n",
    "         \n",
    "    #Concatenating neg. samples of all session interactions because Petastorm data loader \n",
    "    #does not support lists of lists. It will require reshaping neg. samples features inside the Pytorch model\n",
    "    for k in neg_samples_dict:  \n",
    "        neg_samples_dict[k] = np.hstack(neg_samples_dict[k])        \n",
    "\n",
    "    return neg_samples_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_neg_samples([10,20,30, 0, 0], n_samples=2, strategy='popularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_new_rows_to_parquet(new_rows_df, path):\n",
    "    global pq_writer\n",
    "    new_rows_pa = pyarrow.Table.from_pandas(new_rows_df)\n",
    "    if pq_writer is None:\n",
    "        #Creating parent folder recursively\n",
    "        parent_folder = os.path.dirname(os.path.abspath(path))\n",
    "        if not os.path.exists(parent_folder):\n",
    "            os.makedirs(parent_folder)\n",
    "        #Creating parquet file\n",
    "        pq_writer = pq.ParquetWriter(path, new_rows_pa.schema) \n",
    "    pq_writer.write_table(new_rows_pa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generates neg. samples for all sessions and creates new parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_N_SESSIONS_PER_DAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "[Day 0] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n",
      "[Batch 0] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:09,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n",
      "[Batch 1] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:31, 12.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:50, 14.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n",
      "[Batch 3] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:12, 16.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Updating item stats\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-01.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:41, 20.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:05, 21.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:27, 21.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [02:48, 21.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:12, 22.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-01.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [03:41, 20.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 1] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:08,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:29, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:55, 16.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:17, 18.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-02.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:40, 19.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:05, 21.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:25, 20.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [02:47, 21.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:13, 22.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-02.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [03:37, 19.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 2] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:09,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:33, 13.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:01, 18.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:26, 20.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-03.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:55, 22.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:27, 25.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:50, 24.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [03:18, 25.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:49, 27.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-03.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [04:14, 23.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 3] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:07,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:34, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:02, 17.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:20, 17.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-04.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:43, 19.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:06, 20.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:26, 20.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [02:47, 20.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:07, 20.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-04.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [03:29, 19.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 4] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:08,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:30, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:52, 15.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:14, 17.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-05.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:37, 18.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:01, 20.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:22, 20.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [02:47, 22.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:11, 22.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-05.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [03:34, 19.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 5] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:07,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:31, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:57, 16.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:21, 18.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-06.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:46, 20.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:14, 22.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:38, 23.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [03:04, 24.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:29, 24.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-06.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [04:01, 21.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 6] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:10, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:30, 13.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:52, 15.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:14, 17.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-07.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:37, 19.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:00, 20.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:21, 20.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [02:45, 21.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:06, 21.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-07.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [03:30, 19.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 7] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:06,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:30, 11.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:54, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:19, 18.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-08.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:46, 20.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:12, 22.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:35, 22.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [03:00, 23.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:29, 24.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-08.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [04:01, 21.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 8] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:09,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:39, 15.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:07, 19.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:34, 21.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-09.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [02:08, 25.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:34, 25.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:58, 25.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [03:26, 26.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:50, 25.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-09.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [04:16, 23.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 9] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:08,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:31, 12.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:59, 17.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:24, 19.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-10.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:52, 22.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:25, 25.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:53, 26.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [03:24, 27.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:53, 27.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-10.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [04:14, 23.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 10] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:09,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:31, 13.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:56, 16.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:14, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-11.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:41, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:05, 21.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:27, 21.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [02:46, 20.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:11, 22.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-11.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [03:34, 19.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 11] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:08,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:38, 14.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:06, 18.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:34, 21.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-12.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:57, 22.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:27, 24.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:51, 24.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [03:16, 24.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:43, 25.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-12.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [04:08, 22.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 12] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:09,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:36, 14.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:11, 20.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:42, 23.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-13.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [02:16, 27.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:51, 29.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [03:24, 30.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [03:54, 30.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [04:19, 28.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-13.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [04:46, 26.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 13] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:07,  7.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:29, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:51, 15.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:13, 16.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-14.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:36, 18.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [01:59, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:20, 20.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [02:43, 21.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:06, 21.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-14.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [03:32, 19.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 14] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:08,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:29, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:51, 15.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:12, 16.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-15.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:37, 19.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:07, 22.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:36, 24.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [03:05, 25.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:35, 27.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-15.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [04:16, 23.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 15] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:12, 12.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:38, 16.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:13, 22.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:48, 25.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-16.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [02:19, 27.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:55, 30.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [03:23, 29.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [03:46, 27.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [04:12, 27.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-16.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [04:36, 25.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 16] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:08,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:28, 11.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:55, 16.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:21, 19.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-17.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:46, 21.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:11, 22.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:35, 22.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [02:59, 23.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:22, 23.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-17.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [03:48, 20.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 17] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:07,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:33, 12.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:02, 17.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:25, 19.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-18.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:53, 22.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:19, 23.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:45, 24.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [03:05, 22.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:29, 23.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-18.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [03:54, 21.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 18] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:09,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:37, 15.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:04, 18.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:29, 20.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n",
      "[Batch 4] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-19.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:57, 22.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 5\n",
      "[Batch 5] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:27, 24.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:53, 25.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [03:19, 25.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 8\n",
      "[Batch 8] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:45, 25.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 9\n",
      "[Batch 9] Appending new rows with neg samples to parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-19.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [04:14, 23.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 10\n",
      "========================================\n",
      "[Day 19] Loading sessions from parquet: /home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc.parquet/session_start_date=2019-10-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches\n",
      "batch_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:07,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:32, 12.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 2\n",
      "[Batch 2] Updating item stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:02, 17.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:28, 20.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-b68ede6b20eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m#For each row (session)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0minsert_update_session_items_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mappend_session_coocurrences_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-cf66bf355649>\u001b[0m in \u001b[0;36minsert_update_session_items_metadata\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpid\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0mcurr_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitems_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mfirst_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'first_ts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1962\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3562\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3563\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3564\u001b[0;31m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3565\u001b[0m             )\n\u001b[1;32m   3566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    303\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# we will try to copy be-definition here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCExtensionArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36m_try_cast\u001b[0;34m(arr, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_cast_to_integer_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_cast_to_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;31m# Take care in creating object arrays (but iterators are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;31m# supported):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_cast_to_datetime\u001b[0;34m(value, dtype, errors)\u001b[0m\n\u001b[1;32m   1227\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m         \u001b[0mis_datetime64\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_datetime64_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0mis_datetime64tz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0mis_timedelta64\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_timedelta64_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pq_writer = None\n",
    "\n",
    "reset_item_logs_and_statistics()\n",
    "try:\n",
    "    #For each file (day)\n",
    "    for idx_day, input_file in enumerate(input_parquet_files):\n",
    "        print('='*40)\n",
    "        print('[Day {}] Loading sessions from parquet: {}'.format(idx_day, input_file))\n",
    "        output_filename = get_output_path_parquet_neg_samples(input_file)\n",
    "        \n",
    "        if os.path.exists(output_filename):\n",
    "            raise Exception('Output parquet file already exists')\n",
    "        \n",
    "        #Loading parquet file and sorting sessions by timestamp\n",
    "        sessions_df = pd.read_parquet(input_file)\n",
    "        sessions_df.sort_values('session_start_ts', inplace=True)\n",
    "        \n",
    "        #TEMP: Limiting the number of negative samples per day for faster processing\n",
    "        sessions_df = sessions_df[:FIRST_N_SESSIONS_PER_DAY]        \n",
    "                \n",
    "        new_rows = []\n",
    "        \n",
    "        print('Processing batches')\n",
    "        #For each batch\n",
    "        for batch_id, batch in tqdm(enumerate(split_dataframe_into_chuncks_generator(sessions_df, \n",
    "                                                                                chunk_size = BATCH_SIZE))):\n",
    "            print('batch_id', batch_id)            \n",
    "            #For each row (session)\n",
    "            for i, row in batch.iterrows():\n",
    "                insert_update_session_items_metadata(row)\n",
    "                append_session_coocurrences_log(row)\n",
    "                \n",
    "                \n",
    "                #Ignoring first batch (not computing neg. samples nor saving to parquet)\n",
    "                if batch_id > 0:   \n",
    "                    #Generating neg. samples for each interaction in the session\n",
    "                    session_neg_samples_by_pid_dict = generate_neg_samples(row['sess_pid_seq'], \n",
    "                                                                           row['user_pid_seq_bef_sess'],\n",
    "                                                                           NUM_NEG_SAMPLES, \n",
    "                                                                           strategy=NEGATIVE_SAMPLING_STRATEGY\n",
    "                                                                          )\n",
    "                    #Merging user and session features with neg samples for the session\n",
    "                    new_row_with_neg_samples_dict = {**row.to_dict(), **session_neg_samples_by_pid_dict}\n",
    "                    new_rows.append(new_row_with_neg_samples_dict)\n",
    "                    \n",
    "            \n",
    "            #Each N batches updates item statistics (popularity, recency, co-occurrence)\n",
    "            #Ps. Do the update for all the first five batches of the first file , for better sampling\n",
    "            if (batch_id % BATCHES_TO_UPDATE_ITEM_STATS == BATCHES_TO_UPDATE_ITEM_STATS-1) or \\\n",
    "               (idx_day == 0 and batch_id < 5):\n",
    "                print('[Batch {}] Updating item stats'.format(batch_id))\n",
    "                remove_old_interactions(ITEM_STATS_KEEP_LAST_N_DAYS)\n",
    "                if NEGATIVE_SAMPLING_STRATEGY in [RECENT_POPULARITY_SAMPLING, COOCURRENCE_SAMPLING]:\n",
    "                    concat_sessions_coocurrences_log()\n",
    "                    update_items_coocurrences_counts()\n",
    "                    if RECENT_POPULARITY_SAMPLING:\n",
    "                        update_items_recent_popularity()\n",
    "                if NEGATIVE_SAMPLING_STRATEGY == RECENCY_SAMPLING:\n",
    "                    update_items_temporal_relevance_decay()\n",
    "                \n",
    "            #Each N batches appends the new rows with neg. samples to parquet file\n",
    "            if batch_id % BATCHES_TO_APPEND_ROWS_WITH_NEG_SAMPLES == BATCHES_TO_APPEND_ROWS_WITH_NEG_SAMPLES-1: \n",
    "                print('[Batch {}] Appending new rows with neg samples to parquet: {}'.format(batch_id,output_filename))\n",
    "                append_new_rows_to_parquet(pd.DataFrame(new_rows), output_filename)\n",
    "                del(new_rows)\n",
    "                new_rows = []\n",
    "            \n",
    "               \n",
    "        #Save pending rows\n",
    "        if len(new_rows) > 0:\n",
    "            print('[Batch {}] Appending new rows with neg samples to parquet: {}'.format(batch_id,output_filename))\n",
    "            append_new_rows_to_parquet(pd.DataFrame(new_rows), output_filename)\n",
    "            del(new_rows)\n",
    "            new_rows = []\n",
    "            \n",
    "        #Flushing and releasing the current parquet file and proceeding for the new date\n",
    "        pq_writer.close()\n",
    "        pq_writer = None\n",
    "                \n",
    "        del(sessions_df)\n",
    "        gc.collect()\n",
    "finally:\n",
    "    if pq_writer:\n",
    "        pq_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the parquet with Negative samples with Petastorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from petastorm.pytorch import DataLoader\n",
    "from petastorm import make_batch_reader\n",
    "from petastorm.unischema import UnischemaField\n",
    "from petastorm.unischema import Unischema\n",
    "from petastorm.codecs import NdarrayCodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_with_neg_parquet_path = 'file:///home/gmoreira/dataset/ecommerce_preproc_2019-10/ecommerce_preproc_neg_samples_50_strategy_cooccurrence.parquet/session_start_date=2019-10-01_full.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "recsys_schema_full = [\n",
    "  UnischemaField('user_idx', np.int, (), None, True),\n",
    "#   UnischemaField('user_session', str_, (), None, True),\n",
    "  UnischemaField('sess_seq_len', np.int, (), None, False),\n",
    "  UnischemaField('session_start_ts', np.int64, (), None, True),\n",
    "  UnischemaField('user_seq_length_bef_sess', np.int, (), None, False),\n",
    "  UnischemaField('user_elapsed_days_bef_sess', np.float, (), None, True),\n",
    "  UnischemaField('user_elapsed_days_log_bef_sess_norm', np.double, (), None, True),\n",
    "  UnischemaField('sess_pid_seq', np.int64, (None,), None, True),\n",
    "  UnischemaField('sess_etime_seq', np.int64, (None,), None, True),\n",
    "  UnischemaField('sess_etype_seq', np.int, (None,), None, True),\n",
    "  UnischemaField('sess_csid_seq', np.int, (None,), None, True),\n",
    "  UnischemaField('sess_ccid_seq', np.int, (None,), None, True),\n",
    "  UnischemaField('sess_bid_seq', np.int, (None,), None, True),\n",
    "  UnischemaField('sess_price_seq', np.float, (None,), None, True),\n",
    "  UnischemaField('sess_dtime_seq', np.float, (None,), None, True),\n",
    "  UnischemaField('sess_product_recency_seq', np.float, (None,), None, True),\n",
    "  UnischemaField('sess_relative_price_to_avg_category_seq', np.float, (None,), None, True),\n",
    "  UnischemaField('sess_et_hour_sin_seq', np.float, (None,), None, True),\n",
    "  UnischemaField('sess_et_hour_cos_seq', np.float, (None,), None, True),\n",
    "  UnischemaField('sess_et_month_sin_seq', np.float, (None,), None, True),\n",
    "  UnischemaField('sess_et_month_cos_seq', np.float, (None,), None, True),\n",
    "  UnischemaField('sess_et_dayofweek_sin_seq', np.float, (None,), None, True),\n",
    "  UnischemaField('sess_et_dayofweek_cos_seq', np.float, (None,), None, True),\n",
    "  UnischemaField('sess_et_dayofmonth_sin_seq', np.float, (None,), None, True),\n",
    "  UnischemaField('sess_et_dayofmonth_cos_seq', np.float, (None,), None, True),\n",
    "  UnischemaField('user_pid_seq_bef_sess', np.int64, (None,), None, True),\n",
    "  UnischemaField('user_etime_seq_bef_sess', np.int64, (None,), None, True),\n",
    "  UnischemaField('user_etype_seq_bef_sess', np.int, (None,), None, True),\n",
    "  UnischemaField('user_csid_seq_bef_sess', np.int, (None,), None, True),\n",
    "  UnischemaField('user_ccid_seq_bef_sess', np.int, (None,), None, True),\n",
    "  UnischemaField('user_bid_seq_bef_sess', np.int, (None,), None, True),\n",
    "  UnischemaField('user_price_seq_bef_sess', np.float, (None,), None, True),\n",
    "  UnischemaField('user_dtime_seq_bef_sess', np.float, (None,), None, True),\n",
    "  UnischemaField('user_product_recency_seq_bef_sess', np.float, (None,), None, True),\n",
    "  UnischemaField('user_relative_price_to_avg_category_seq_bef_sess', np.float, (None,), None, True),\n",
    "  UnischemaField('user_et_hour_sin_seq_bef_sess', np.float, (None,), None, True),\n",
    "  UnischemaField('user_et_hour_cos_seq_bef_sess', np.float, (None,), None, True),\n",
    "  UnischemaField('user_et_month_sin_seq_bef_sess', np.float, (None,), None, True),\n",
    "  UnischemaField('user_et_month_cos_seq_bef_sess', np.float, (None,), None, True),\n",
    "  UnischemaField('user_et_dayofweek_sin_seq_bef_sess', np.float, (None,), None, True),\n",
    "  UnischemaField('user_et_dayofweek_cos_seq_bef_sess', np.float, (None,), None, True),\n",
    "  UnischemaField('user_et_dayofmonth_sin_seq_bef_sess', np.float, (None,), None, True),\n",
    "  UnischemaField('user_et_dayofmonth_cos_seq_bef_sess', np.float, (None,), None, True),\n",
    "  UnischemaField('user_et_dayofmonth_cos_seq_bef_sess', np.float, (None,), None, True),\n",
    "  UnischemaField('sess_neg_pids', np.int, (None,), None, True),\n",
    "  UnischemaField('sess_neg_csid', np.int, (None,), None, True),\n",
    "  UnischemaField('sess_neg_ccid', np.int, (None,), None, True),\n",
    "  UnischemaField('sess_neg_bid', np.int, (None,), None, True),\n",
    "  UnischemaField('sess_neg_price', np.float, (None,), None, True),\n",
    "  UnischemaField('sess_neg_relative_price_to_avg_category', np.float, (None,), None, True),\n",
    "  UnischemaField('sess_neg_product_recency', np.float, (None,), None, True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmoreira/anaconda3/envs/transf4rec/lib/python3.7/site-packages/petastorm/unischema.py:197: UserWarning: Can not create dynamic property user_et_dayofmonth_cos_seq_bef_sess because it conflicts with an existing property of Unischema\n",
      "  'Unischema').format(f.name))\n",
      "/home/gmoreira/anaconda3/envs/transf4rec/lib/python3.7/site-packages/petastorm/arrow_reader_worker.py:53: FutureWarning: Calling .data on ChunkedArray is provided for compatibility after Column was removed, simply drop this attribute\n",
      "  column_as_pandas = column.data.chunks[0].to_pandas()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:0\n",
      "{'user_idx': tensor([550479254, 547827437]), 'sess_seq_len': tensor([21,  3]), 'session_start_ts': tensor([1569921441, 1569921441]), 'user_seq_length_bef_sess': tensor([0, 0]), 'user_elapsed_days_bef_sess': tensor([nan, nan], dtype=torch.float64), 'user_elapsed_days_log_bef_sess_norm': tensor([nan, nan], dtype=torch.float64), 'sess_pid_seq': tensor([[125685,   5713,   3066,  11869,  10670,   4312,  19814,  63599,   8931,\n",
      "           6909,   7571,   3390,   1697,   3616,  21046,   2666,   7386,   3976,\n",
      "          23679,  28513],\n",
      "        [   515,     57,    331,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0]]), 'sess_etime_seq': tensor([[1569921441, 1569921527, 1569921549, 1569921628, 1569921649, 1569921670,\n",
      "         1569921712, 1569921752, 1569921793, 1569921955, 1569922051, 1569922061,\n",
      "         1569922096, 1569922146, 1569922168, 1569922273, 1569922283, 1569922301,\n",
      "         1569922345, 1569922393],\n",
      "        [1569921441, 1569921463, 1569921471,          0,          0,          0,\n",
      "                  0,          0,          0,          0,          0,          0,\n",
      "                  0,          0,          0,          0,          0,          0,\n",
      "                  0,          0]]), 'sess_etype_seq': tensor([[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "        [2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       dtype=torch.int32), 'sess_csid_seq': tensor([[362, 159, 159, 159, 159, 159, 159, 159, 159, 159,  88, 205, 159,  88,\n",
      "          88,  28,  28,  28,  28,  28],\n",
      "        [  8,   8,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0]], dtype=torch.int32), 'sess_ccid_seq': tensor([[131, 131, 131, 131, 131, 131, 131, 131, 131, 131,  14, 131, 131,  14,\n",
      "          14,  18,  18,  18,  18,  18],\n",
      "        [  8,   8,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0]], dtype=torch.int32), 'sess_bid_seq': tensor([[4305, 4305,   32, 4305, 4305, 4305, 4305, 4305, 4305, 4305, 4305,  282,\n",
      "           32, 4305, 4305, 4305, 4305,  132, 4305, 4305],\n",
      "        [   2,    2,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]], dtype=torch.int32), 'sess_price_seq': tensor([[-2.5044,  0.8894,  0.7539,  1.2824,  0.8940,  0.8894,  1.6242,  0.2981,\n",
      "          2.0262,  2.1064, -0.1115, -1.0654,  0.5714, -0.0960, -0.0823,  1.4385,\n",
      "          0.9771,  0.6699,  1.0600,  1.0333],\n",
      "        [-0.4354, -0.7092, -0.7061,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000]]), 'sess_dtime_seq': tensor([[-0.0230, -0.0144, -0.0208, -0.0151, -0.0209, -0.0209, -0.0188, -0.0198,\n",
      "         -0.0189, -0.0197, -0.0134, -0.0220, -0.0195, -0.0204, -0.0208, -0.0125,\n",
      "         -0.0220, -0.0212, -0.0186, -0.0182],\n",
      "        [-0.0230, -0.0208, -0.0222,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000]]), 'sess_product_recency_seq': tensor([[-3.5630, -3.5637, -3.5722, -3.5630, -3.5702, -3.5588, -3.5685, -3.7386,\n",
      "         -3.5727, -3.5590, -3.4702, -3.8292, -3.5529, -3.5856, -3.6987, -3.5762,\n",
      "         -3.5526, -3.5521, -3.5541, -3.5564],\n",
      "        [-3.5637, -3.5573, -3.5698,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000]]), 'sess_relative_price_to_avg_category_seq': tensor([[-0.6317, -0.1639, -0.2915,  0.3509, -0.1591, -0.1639,  1.0500, -0.5942,\n",
      "          2.3469,  2.6908, -0.1142,  0.0661, -0.4331, -0.0972, -0.0818,  0.4311,\n",
      "         -0.1852, -0.4401, -0.0983, -0.1273],\n",
      "        [-0.5030, -0.6456, -0.6442,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000]]), 'sess_et_hour_sin_seq': tensor([[0.7071, 0.7071, 0.7071, 0.7071, 0.7071, 0.7071, 0.7071, 0.7071, 0.7071,\n",
      "         0.7071, 0.7071, 0.7071, 0.7071, 0.7071, 0.7071, 0.7071, 0.7071, 0.7071,\n",
      "         0.7071, 0.7071],\n",
      "        [0.7071, 0.7071, 0.7071, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]]), 'sess_et_hour_cos_seq': tensor([[-0.7071, -0.7071, -0.7071, -0.7071, -0.7071, -0.7071, -0.7071, -0.7071,\n",
      "         -0.7071, -0.7071, -0.7071, -0.7071, -0.7071, -0.7071, -0.7071, -0.7071,\n",
      "         -0.7071, -0.7071, -0.7071, -0.7071],\n",
      "        [-0.7071, -0.7071, -0.7071,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000]]), 'sess_et_month_sin_seq': tensor([[-0.8660, -0.8660, -0.8660, -0.8660, -0.8660, -0.8660, -0.8660, -0.8660,\n",
      "         -0.8660, -0.8660, -0.8660, -0.8660, -0.8660, -0.8660, -0.8660, -0.8660,\n",
      "         -0.8660, -0.8660, -0.8660, -0.8660],\n",
      "        [-0.8660, -0.8660, -0.8660,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000]]), 'sess_et_month_cos_seq': tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]]), 'sess_et_dayofweek_sin_seq': tensor([[0.4339, 0.4339, 0.4339, 0.4339, 0.4339, 0.4339, 0.4339, 0.4339, 0.4339,\n",
      "         0.4339, 0.4339, 0.4339, 0.4339, 0.4339, 0.4339, 0.4339, 0.4339, 0.4339,\n",
      "         0.4339, 0.4339],\n",
      "        [0.4339, 0.4339, 0.4339, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]]), 'sess_et_dayofweek_cos_seq': tensor([[-0.9010, -0.9010, -0.9010, -0.9010, -0.9010, -0.9010, -0.9010, -0.9010,\n",
      "         -0.9010, -0.9010, -0.9010, -0.9010, -0.9010, -0.9010, -0.9010, -0.9010,\n",
      "         -0.9010, -0.9010, -0.9010, -0.9010],\n",
      "        [-0.9010, -0.9010, -0.9010,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000]]), 'sess_et_dayofmonth_sin_seq': tensor([[0.2013, 0.2013, 0.2013, 0.2013, 0.2013, 0.2013, 0.2013, 0.2013, 0.2013,\n",
      "         0.2013, 0.2013, 0.2013, 0.2013, 0.2013, 0.2013, 0.2013, 0.2013, 0.2013,\n",
      "         0.2013, 0.2013],\n",
      "        [0.2013, 0.2013, 0.2013, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]]), 'sess_et_dayofmonth_cos_seq': tensor([[0.9795, 0.9795, 0.9795, 0.9795, 0.9795, 0.9795, 0.9795, 0.9795, 0.9795,\n",
      "         0.9795, 0.9795, 0.9795, 0.9795, 0.9795, 0.9795, 0.9795, 0.9795, 0.9795,\n",
      "         0.9795, 0.9795],\n",
      "        [0.9795, 0.9795, 0.9795, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]]), 'user_pid_seq_bef_sess': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'user_etime_seq_bef_sess': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'user_etype_seq_bef_sess': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       dtype=torch.int32), 'user_csid_seq_bef_sess': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       dtype=torch.int32), 'user_ccid_seq_bef_sess': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       dtype=torch.int32), 'user_bid_seq_bef_sess': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
      "       dtype=torch.int32), 'user_price_seq_bef_sess': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'user_dtime_seq_bef_sess': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'user_product_recency_seq_bef_sess': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'user_relative_price_to_avg_category_seq_bef_sess': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'user_et_hour_sin_seq_bef_sess': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'user_et_hour_cos_seq_bef_sess': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'user_et_month_sin_seq_bef_sess': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'user_et_month_cos_seq_bef_sess': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'user_et_dayofweek_sin_seq_bef_sess': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'user_et_dayofweek_cos_seq_bef_sess': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'user_et_dayofmonth_sin_seq_bef_sess': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'user_et_dayofmonth_cos_seq_bef_sess': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'sess_neg_pids': tensor([[173824,    131,      6,  ...,  26878,      0,      0],\n",
      "        [ 36353,   1031,    524,  ...,      0,      0,      0]]), 'sess_neg_csid': tensor([[601,  10,   2,  ...,  28,   0,   0],\n",
      "        [  8,   8,   8,  ...,   0,   0,   0]]), 'sess_neg_ccid': tensor([[103,   3,   2,  ...,  18,   0,   0],\n",
      "        [  8,   8,   8,  ...,   0,   0,   0]]), 'sess_neg_bid': tensor([[ 793,    4,    2,  ..., 4305,    0,    0],\n",
      "        [ 145,    2,   47,  ...,    0,    0,    0]]), 'sess_neg_price': tensor([[-0.9275, -0.6612,  0.5109,  ...,  1.6356,  0.0000,  0.0000],\n",
      "        [-0.4936, -0.3250, -0.1989,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64), 'sess_neg_relative_price_to_avg_category': tensor([[ 0.2254, -0.7917, -0.4009,  ...,  0.8199,  0.0000,  0.0000],\n",
      "        [-0.5374, -0.4307, -0.3352,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64), 'sess_neg_product_recency': tensor([[-3.8576, -3.4990, -3.4690,  ..., -3.8576,  0.0000,  0.0000],\n",
      "        [-3.7296, -3.5652, -3.5564,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       dtype=torch.float64)}\n",
      "torch.Size([2, 1000])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-da8077b5c1a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sess_neg_product_recency'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/transf4rec/lib/python3.7/site-packages/petastorm/pytorch.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transf4rec/lib/python3.7/site-packages/petastorm/reader.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;34m\"\"\"Joins all worker threads/processes. Will block until all worker workers have been fully terminated.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transf4rec/lib/python3.7/site-packages/petastorm/workers_pool/thread_pool.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misAlive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profiling_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transf4rec/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/transf4rec/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with DataLoader(\n",
    "    make_batch_reader(input_with_neg_parquet_path, \n",
    "                num_epochs=1,\n",
    "                # transform_spec=transform\n",
    "                schema_fields=recsys_schema_full,\n",
    "    ), batch_size=2) as train_loader:\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        print(\"i:{}\".format(i))\n",
    "        print(batch)\n",
    "        print(batch['sess_neg_product_recency'].shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/home/gmoreira/dataset/ecommerce_preproc_with_neg_samples/ecommerce_preproc_neg_samples_50_strategy_uniform/session_start_date=2019-10-01-train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_idx', 'user_session', 'sess_seq_len', 'session_start_ts',\n",
       "       'user_seq_length_bef_sess', 'user_elapsed_days_bef_sess',\n",
       "       'user_elapsed_days_log_bef_sess_norm', 'sess_pid_seq', 'sess_etime_seq',\n",
       "       'sess_etype_seq', 'sess_csid_seq', 'sess_ccid_seq', 'sess_bid_seq',\n",
       "       'sess_price_seq', 'sess_dtime_seq', 'sess_product_recency_seq',\n",
       "       'sess_relative_price_to_avg_category_seq', 'sess_et_hour_sin_seq',\n",
       "       'sess_et_hour_cos_seq', 'sess_et_month_sin_seq',\n",
       "       'sess_et_month_cos_seq', 'sess_et_dayofweek_sin_seq',\n",
       "       'sess_et_dayofweek_cos_seq', 'sess_et_dayofmonth_sin_seq',\n",
       "       'sess_et_dayofmonth_cos_seq', 'user_pid_seq_bef_sess',\n",
       "       'user_etime_seq_bef_sess', 'user_etype_seq_bef_sess',\n",
       "       'user_csid_seq_bef_sess', 'user_ccid_seq_bef_sess',\n",
       "       'user_bid_seq_bef_sess', 'user_price_seq_bef_sess',\n",
       "       'user_dtime_seq_bef_sess', 'user_product_recency_seq_bef_sess',\n",
       "       'user_relative_price_to_avg_category_seq_bef_sess',\n",
       "       'user_et_hour_sin_seq_bef_sess', 'user_et_hour_cos_seq_bef_sess',\n",
       "       'user_et_month_sin_seq_bef_sess', 'user_et_month_cos_seq_bef_sess',\n",
       "       'user_et_dayofweek_sin_seq_bef_sess',\n",
       "       'user_et_dayofweek_cos_seq_bef_sess',\n",
       "       'user_et_dayofmonth_sin_seq_bef_sess',\n",
       "       'user_et_dayofmonth_cos_seq_bef_sess', 'sess_neg_pids',\n",
       "       'sess_neg_sess_csid_seq', 'sess_neg_sess_ccid_seq',\n",
       "       'sess_neg_sess_bid_seq', 'sess_neg_sess_price_seq',\n",
       "       'sess_neg_sess_relative_price_to_avg_category_seq',\n",
       "       'sess_neg_sess_product_recency_seq'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_idx                                              int64\n",
       "user_session                                         object\n",
       "sess_seq_len                                          int64\n",
       "session_start_ts                                      int64\n",
       "user_seq_length_bef_sess                              int64\n",
       "user_elapsed_days_bef_sess                          float64\n",
       "user_elapsed_days_log_bef_sess_norm                 float64\n",
       "sess_pid_seq                                         object\n",
       "sess_etime_seq                                       object\n",
       "sess_etype_seq                                       object\n",
       "sess_csid_seq                                        object\n",
       "sess_ccid_seq                                        object\n",
       "sess_bid_seq                                         object\n",
       "sess_price_seq                                       object\n",
       "sess_dtime_seq                                       object\n",
       "sess_product_recency_seq                             object\n",
       "sess_relative_price_to_avg_category_seq              object\n",
       "sess_et_hour_sin_seq                                 object\n",
       "sess_et_hour_cos_seq                                 object\n",
       "sess_et_month_sin_seq                                object\n",
       "sess_et_month_cos_seq                                object\n",
       "sess_et_dayofweek_sin_seq                            object\n",
       "sess_et_dayofweek_cos_seq                            object\n",
       "sess_et_dayofmonth_sin_seq                           object\n",
       "sess_et_dayofmonth_cos_seq                           object\n",
       "user_pid_seq_bef_sess                                object\n",
       "user_etime_seq_bef_sess                              object\n",
       "user_etype_seq_bef_sess                              object\n",
       "user_csid_seq_bef_sess                               object\n",
       "user_ccid_seq_bef_sess                               object\n",
       "user_bid_seq_bef_sess                                object\n",
       "user_price_seq_bef_sess                              object\n",
       "user_dtime_seq_bef_sess                              object\n",
       "user_product_recency_seq_bef_sess                    object\n",
       "user_relative_price_to_avg_category_seq_bef_sess     object\n",
       "user_et_hour_sin_seq_bef_sess                        object\n",
       "user_et_hour_cos_seq_bef_sess                        object\n",
       "user_et_month_sin_seq_bef_sess                       object\n",
       "user_et_month_cos_seq_bef_sess                       object\n",
       "user_et_dayofweek_sin_seq_bef_sess                   object\n",
       "user_et_dayofweek_cos_seq_bef_sess                   object\n",
       "user_et_dayofmonth_sin_seq_bef_sess                  object\n",
       "user_et_dayofmonth_cos_seq_bef_sess                  object\n",
       "sess_neg_pids                                        object\n",
       "sess_neg_sess_csid_seq                               object\n",
       "sess_neg_sess_ccid_seq                               object\n",
       "sess_neg_sess_bid_seq                                object\n",
       "sess_neg_sess_price_seq                              object\n",
       "sess_neg_sess_relative_price_to_avg_category_seq     object\n",
       "sess_neg_sess_product_recency_seq                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 527,   23,    2,   84,   22,   20,   53,  461,  779,  343,  751,\n",
       "       4305, 4305, 4305, 4305,    2, 4305,  273,   33,   18, 4305,    8,\n",
       "       4305, 4305,  603,   78,   18,  224, 4305,    7,    4, 4305,    6,\n",
       "       4305,   30,   53,  122,  309,  238,  138, 4305,  110,    5, 4305,\n",
       "         18,  394,    2,    7, 4305, 2326,   27,    3,  549,  207,  603,\n",
       "        104,  326,  100,  175,    2, 4305, 1052,  527,  114, 4305,    2,\n",
       "         49,   44, 4305, 1021,  173, 4305,  187, 4305,    8, 4305, 4305,\n",
       "       4305, 1390,  148,    3,    8,    3,    3,    2, 4305,   21,    7,\n",
       "       4305,   40,   29,   53,  338,  152,    8,  165,  102,    8,   53,\n",
       "         47,    3, 4305, 4305,   27, 4305, 4305,   31,   10, 4305,  384,\n",
       "       4305,  603, 4305, 4305, 4305,  319,   79,  219,    3,    3,    3,\n",
       "         43, 4305,   11,   13, 4305,   21,  167,   62, 4305,    4,    9,\n",
       "        110,  561,  359,   86,   20, 4305,   40,   43,  170,  829,   66,\n",
       "       4305, 4305,    6,  301, 4305,   68, 4305,  256,  349,    4,   26,\n",
       "        212,   35, 1363,  757,    3,  201, 4305,   65,   42, 4305, 4305,\n",
       "        193,   50,    4, 1137,   28,  868,   37,   11,    4, 4305,   23,\n",
       "         12,  241,   27,   15, 4305, 4305,   29,    7,    3,   93, 4305,\n",
       "       4305,  702,   26, 4305,   65,  480,   34, 4305,   20,   15,   81,\n",
       "         64,  257,    5, 4305, 4305, 4305,    3,   25, 4305, 4305, 4305,\n",
       "        254,    2,   26,    2,   12,    3,  124,  157, 4305,   27, 4305,\n",
       "       4305,    6, 2394,   84, 4305,  181, 4305,  576,   78, 4305, 4305,\n",
       "         24,  261,  243, 4305,   29,   62,    4, 4305,    2,   47,  123,\n",
       "         12, 1112,   91,   14,  480,    4, 4305, 4305,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sess_neg_sess_bid_seq'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4305.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sess_neg_sess_bid_seq'].values[0][155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_idx</th>\n",
       "      <th>user_session</th>\n",
       "      <th>sess_seq_len</th>\n",
       "      <th>session_start_ts</th>\n",
       "      <th>user_seq_length_bef_sess</th>\n",
       "      <th>user_elapsed_days_bef_sess</th>\n",
       "      <th>user_elapsed_days_log_bef_sess_norm</th>\n",
       "      <th>sess_pid_seq</th>\n",
       "      <th>sess_etime_seq</th>\n",
       "      <th>sess_etype_seq</th>\n",
       "      <th>...</th>\n",
       "      <th>user_et_dayofweek_cos_seq_bef_sess</th>\n",
       "      <th>user_et_dayofmonth_sin_seq_bef_sess</th>\n",
       "      <th>user_et_dayofmonth_cos_seq_bef_sess</th>\n",
       "      <th>sess_neg_pids</th>\n",
       "      <th>sess_neg_sess_csid_seq</th>\n",
       "      <th>sess_neg_sess_ccid_seq</th>\n",
       "      <th>sess_neg_sess_bid_seq</th>\n",
       "      <th>sess_neg_sess_price_seq</th>\n",
       "      <th>sess_neg_sess_relative_price_to_avg_category_seq</th>\n",
       "      <th>sess_neg_sess_product_recency_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>555648057</td>\n",
       "      <td>98499c8f-ad2d-45bd-99c9-d9947ad4784e</td>\n",
       "      <td>5</td>\n",
       "      <td>1569938266</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3995, 168, 957, 337, 1726, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1569938266, 1569938319, 1569938353, 156993839...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[5976, 11966, 48, 30747, 2786, 5564, 60760, 22...</td>\n",
       "      <td>[146, 12, 4, 3, 34, 15, 31, 12, 74, 52, 314, 7...</td>\n",
       "      <td>[48, 3, 4, 131, 23, 131, 13, 3, 13, 131, 86, 1...</td>\n",
       "      <td>[527, 23, 2, 84, 22, 20, 53, 461, 779, 343, 75...</td>\n",
       "      <td>[-1.2072219848632812, -0.9228723049163818, 0.9...</td>\n",
       "      <td>[-0.8343976736068726, -0.8237003684043884, 0.0...</td>\n",
       "      <td>[-3.5283703804016113, -3.647977113723755, -3.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>555698781</td>\n",
       "      <td>ef1abf6d-1b24-4cb8-b678-c9550bc33d7d</td>\n",
       "      <td>5</td>\n",
       "      <td>1569945681</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[4097, 10341, 6030, 11568, 8499, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[1569945681, 1569945825, 1569945848, 156994588...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[41122, 3497, 1254, 135, 29631, 29708, 38921, ...</td>\n",
       "      <td>[235, 37, 19, 2, 74, 152, 235, 91, 16, 2, 380,...</td>\n",
       "      <td>[131, 131, 12, 2, 13, 131, 131, 131, 131, 2, 1...</td>\n",
       "      <td>[1139, 61, 160, 3, 176, 4305, 503, 1934, 4305,...</td>\n",
       "      <td>[-2.5214123725891113, 0.11688324809074402, -0....</td>\n",
       "      <td>[-0.5392028093338013, -0.3629242181777954, -0....</td>\n",
       "      <td>[-3.857556104660034, -3.5666608810424805, -3.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>529338550</td>\n",
       "      <td>875a7800-5550-4aa3-85fe-7915b5f04023</td>\n",
       "      <td>6</td>\n",
       "      <td>1569965750</td>\n",
       "      <td>2</td>\n",
       "      <td>0.291377</td>\n",
       "      <td>-0.702407</td>\n",
       "      <td>[35528, 7536, 22620, 19725, 27659, 71909, 0, 0...</td>\n",
       "      <td>[1569965750, 1569965775, 1569965821, 156996585...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.90096885, -0.90096885, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.20129852, 0.20129852, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.9795299, 0.9795299, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[7914, 11007, 833, 45487, 11343, 5887, 39782, ...</td>\n",
       "      <td>[3, 27, 4, 134, 72, 38, 303, 198, 110, 302, 24...</td>\n",
       "      <td>[131, 14, 4, 55, 49, 17, 131, 131, 131, 131, 9...</td>\n",
       "      <td>[84, 29, 2, 24, 589, 4305, 4305, 197, 4305, 43...</td>\n",
       "      <td>[-0.474873423576355, -0.36009541153907776, 2.0...</td>\n",
       "      <td>[0.32676804065704346, -0.5733218789100647, 2.9...</td>\n",
       "      <td>[-3.857556104660034, -3.6964993476867676, -3.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555725229</td>\n",
       "      <td>cd2621a6-61e4-465b-8aba-57fe2359a33c</td>\n",
       "      <td>5</td>\n",
       "      <td>1569950568</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[267, 14, 130, 115, 74, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[1569950568, 1569950635, 1569950718, 156995100...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[51246, 1148, 2590, 67453, 163803, 382, 4598, ...</td>\n",
       "      <td>[196, 10, 196, 23, 95, 24, 230, 2, 15, 125, 10...</td>\n",
       "      <td>[131, 3, 131, 11, 53, 9, 88, 2, 131, 54, 3, 5,...</td>\n",
       "      <td>[121, 3, 73, 16, 531, 4305, 4305, 4, 20, 4305,...</td>\n",
       "      <td>[-2.759387969970703, 1.171530842781067, 1.3147...</td>\n",
       "      <td>[-0.9487777352333069, 0.9699004888534546, 8.01...</td>\n",
       "      <td>[-3.857556104660034, -3.6995019912719727, -3.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>522023225</td>\n",
       "      <td>dcb6e777-0bdf-4598-9c1b-e219499ef73f</td>\n",
       "      <td>2</td>\n",
       "      <td>1569943802</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1569943802, 1569943852, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1024, 18499, 1874, 40394, 4486, 2320, 2355, 4...</td>\n",
       "      <td>[186, 54, 24, 9, 33, 24, 128, 2, 57, 207, 8, 1...</td>\n",
       "      <td>[131, 131, 9, 131, 22, 9, 65, 2, 131, 41, 8, 5...</td>\n",
       "      <td>[10, 4305, 19, 4305, 4305, 4305, 4305, 2, 17, ...</td>\n",
       "      <td>[0.7368451356887817, -0.6964377164840698, 0.58...</td>\n",
       "      <td>[0.5878480672836304, -0.6419907808303833, 0.20...</td>\n",
       "      <td>[-3.4588608741760254, -3.8255484104156494, -3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>555652474</td>\n",
       "      <td>b808ab70-23a7-405f-a9be-0ddae7e05a92</td>\n",
       "      <td>3</td>\n",
       "      <td>1569937871</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[22, 78, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[1569937871, 1569937963, 1569937984, 0, 0, 0, ...</td>\n",
       "      <td>[2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[5259, 51167, 170, 5271, 12821, 124, 767, 5527...</td>\n",
       "      <td>[7, 58, 2, 27, 184, 14, 3, 83, 49, 2, 14, 22, ...</td>\n",
       "      <td>[10, 131, 2, 14, 131, 131, 131, 41, 28, 2, 131...</td>\n",
       "      <td>[19, 4305, 9, 48, 4, 44, 67, 4305, 20, 3, 8, 6...</td>\n",
       "      <td>[0.49252572655677795, 1.1661357879638672, 0.75...</td>\n",
       "      <td>[-0.16759197413921356, 0.17139066755771637, -0...</td>\n",
       "      <td>[-3.6690099239349365, -3.7491071224212646, -3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>522138637</td>\n",
       "      <td>437d65f0-d3da-41c1-99df-4157cd95f82d</td>\n",
       "      <td>2</td>\n",
       "      <td>1569953816</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[55, 81, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
       "      <td>[1569953816, 1569954009, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[67613, 37629, 2535, 77213, 3748, 1047, 1978, ...</td>\n",
       "      <td>[25, 109, 2, 13, 81, 4, 2, 2, 8, 196, 20, 3, 3...</td>\n",
       "      <td>[15, 131, 2, 131, 131, 4, 2, 2, 8, 131, 131, 1...</td>\n",
       "      <td>[4305, 4305, 4, 39, 42, 268, 4, 3, 47, 4305, 2...</td>\n",
       "      <td>[-0.43555590510368347, -1.1716824769973755, -0...</td>\n",
       "      <td>[-0.6772119402885437, 0.016083568334579468, -0...</td>\n",
       "      <td>[-3.857556104660034, -3.857556104660034, -3.53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>514316046</td>\n",
       "      <td>d9a8115b-d69d-4e71-99c7-0a1347e11695</td>\n",
       "      <td>4</td>\n",
       "      <td>1569931744</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[6162, 18467, 16081, 61097, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1569931744, 1569931786, 1569931815, 156993183...</td>\n",
       "      <td>[2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[40408, 80057, 126, 82433, 6840, 122140, 8642,...</td>\n",
       "      <td>[30, 182, 2, 18, 2, 28, 16, 2, 21, 4, 103, 4, ...</td>\n",
       "      <td>[7, 131, 2, 7, 2, 18, 131, 2, 16, 4, 52, 4, 7,...</td>\n",
       "      <td>[4305, 4305, 2, 247, 3, 4305, 112, 4, 82, 2, 4...</td>\n",
       "      <td>[-0.45678481459617615, -0.22726204991340637, 1...</td>\n",
       "      <td>[0.04079359769821167, -0.2926800847053528, 0.3...</td>\n",
       "      <td>[-3.7937638759613037, -3.637340545654297, -3.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>551450418</td>\n",
       "      <td>1abd871b-71c7-44ea-bd8a-b9eb0f2e1034</td>\n",
       "      <td>5</td>\n",
       "      <td>1569945137</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>-0.947112</td>\n",
       "      <td>[265, 373, 572, 588, 990, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1569945137, 1569945148, 1569945179, 156994519...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.90096885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>[0.20129852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>[0.9795299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[97982, 16640, 17849, 2010, 17409, 1101, 2126,...</td>\n",
       "      <td>[317, 369, 15, 33, 12, 39, 2, 2, 23, 235, 85, ...</td>\n",
       "      <td>[24, 131, 131, 22, 3, 25, 2, 2, 11, 131, 131, ...</td>\n",
       "      <td>[1367, 547, 65, 107, 4305, 110, 98, 4305, 11, ...</td>\n",
       "      <td>[-1.5836411714553833, -3.095940351486206, 0.03...</td>\n",
       "      <td>[-0.5201225876808167, -0.9587899446487427, -0....</td>\n",
       "      <td>[-3.470968008041382, -3.3620927333831787, -3.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>514864236</td>\n",
       "      <td>5bd4d8fc-7ab8-4f6c-b402-677de289e620</td>\n",
       "      <td>2</td>\n",
       "      <td>1569939642</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[4132, 92693, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1569939642, 1569939757, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[2815, 2102, 29493, 707, 32926, 1935, 34207, 3...</td>\n",
       "      <td>[9, 2, 109, 4, 229, 5, 47, 116, 46, 2, 10, 34,...</td>\n",
       "      <td>[131, 2, 131, 4, 131, 5, 31, 60, 30, 2, 3, 23,...</td>\n",
       "      <td>[4305, 86, 4305, 93, 2431, 21, 370, 2, 89, 68,...</td>\n",
       "      <td>[-0.21116256713867188, -0.3686261773109436, -1...</td>\n",
       "      <td>[-0.5457116961479187, -0.7962461113929749, 0.0...</td>\n",
       "      <td>[-3.4238157272338867, -3.3644144535064697, -3....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_idx                          user_session  sess_seq_len  \\\n",
       "0    555648057  98499c8f-ad2d-45bd-99c9-d9947ad4784e             5   \n",
       "1    555698781  ef1abf6d-1b24-4cb8-b678-c9550bc33d7d             5   \n",
       "2    529338550  875a7800-5550-4aa3-85fe-7915b5f04023             6   \n",
       "3    555725229  cd2621a6-61e4-465b-8aba-57fe2359a33c             5   \n",
       "4    522023225  dcb6e777-0bdf-4598-9c1b-e219499ef73f             2   \n",
       "..         ...                                   ...           ...   \n",
       "995  555652474  b808ab70-23a7-405f-a9be-0ddae7e05a92             3   \n",
       "996  522138637  437d65f0-d3da-41c1-99df-4157cd95f82d             2   \n",
       "997  514316046  d9a8115b-d69d-4e71-99c7-0a1347e11695             4   \n",
       "998  551450418  1abd871b-71c7-44ea-bd8a-b9eb0f2e1034             5   \n",
       "999  514864236  5bd4d8fc-7ab8-4f6c-b402-677de289e620             2   \n",
       "\n",
       "     session_start_ts  user_seq_length_bef_sess  user_elapsed_days_bef_sess  \\\n",
       "0          1569938266                         0                         NaN   \n",
       "1          1569945681                         0                         NaN   \n",
       "2          1569965750                         2                    0.291377   \n",
       "3          1569950568                         0                         NaN   \n",
       "4          1569943802                         0                         NaN   \n",
       "..                ...                       ...                         ...   \n",
       "995        1569937871                         0                         NaN   \n",
       "996        1569953816                         0                         NaN   \n",
       "997        1569931744                         0                         NaN   \n",
       "998        1569945137                         1                    0.009375   \n",
       "999        1569939642                         0                         NaN   \n",
       "\n",
       "     user_elapsed_days_log_bef_sess_norm  \\\n",
       "0                                    NaN   \n",
       "1                                    NaN   \n",
       "2                              -0.702407   \n",
       "3                                    NaN   \n",
       "4                                    NaN   \n",
       "..                                   ...   \n",
       "995                                  NaN   \n",
       "996                                  NaN   \n",
       "997                                  NaN   \n",
       "998                            -0.947112   \n",
       "999                                  NaN   \n",
       "\n",
       "                                          sess_pid_seq  \\\n",
       "0    [3995, 168, 957, 337, 1726, 0, 0, 0, 0, 0, 0, ...   \n",
       "1    [4097, 10341, 6030, 11568, 8499, 0, 0, 0, 0, 0...   \n",
       "2    [35528, 7536, 22620, 19725, 27659, 71909, 0, 0...   \n",
       "3    [267, 14, 130, 115, 74, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "4    [2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "..                                                 ...   \n",
       "995  [22, 78, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "996  [55, 81, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
       "997  [6162, 18467, 16081, 61097, 0, 0, 0, 0, 0, 0, ...   \n",
       "998  [265, 373, 572, 588, 990, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "999  [4132, 92693, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                        sess_etime_seq  \\\n",
       "0    [1569938266, 1569938319, 1569938353, 156993839...   \n",
       "1    [1569945681, 1569945825, 1569945848, 156994588...   \n",
       "2    [1569965750, 1569965775, 1569965821, 156996585...   \n",
       "3    [1569950568, 1569950635, 1569950718, 156995100...   \n",
       "4    [1569943802, 1569943852, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "..                                                 ...   \n",
       "995  [1569937871, 1569937963, 1569937984, 0, 0, 0, ...   \n",
       "996  [1569953816, 1569954009, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "997  [1569931744, 1569931786, 1569931815, 156993183...   \n",
       "998  [1569945137, 1569945148, 1569945179, 156994519...   \n",
       "999  [1569939642, 1569939757, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                        sess_etype_seq  ...  \\\n",
       "0    [2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ...   \n",
       "1    [2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ...   \n",
       "2    [2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ...   \n",
       "3    [2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ...   \n",
       "4    [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ...   \n",
       "..                                                 ...  ...   \n",
       "995  [2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ...   \n",
       "996  [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ...   \n",
       "997  [2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ...   \n",
       "998  [2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ...   \n",
       "999  [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ...   \n",
       "\n",
       "                    user_et_dayofweek_cos_seq_bef_sess  \\\n",
       "0    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2    [-0.90096885, -0.90096885, 0.0, 0.0, 0.0, 0.0,...   \n",
       "3    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "..                                                 ...   \n",
       "995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "998  [-0.90096885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....   \n",
       "999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                   user_et_dayofmonth_sin_seq_bef_sess  \\\n",
       "0    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2    [0.20129852, 0.20129852, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "3    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "..                                                 ...   \n",
       "995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "998  [0.20129852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                   user_et_dayofmonth_cos_seq_bef_sess  \\\n",
       "0    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2    [0.9795299, 0.9795299, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "3    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "..                                                 ...   \n",
       "995  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "996  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "997  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "998  [0.9795299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "999  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                         sess_neg_pids  \\\n",
       "0    [5976, 11966, 48, 30747, 2786, 5564, 60760, 22...   \n",
       "1    [41122, 3497, 1254, 135, 29631, 29708, 38921, ...   \n",
       "2    [7914, 11007, 833, 45487, 11343, 5887, 39782, ...   \n",
       "3    [51246, 1148, 2590, 67453, 163803, 382, 4598, ...   \n",
       "4    [1024, 18499, 1874, 40394, 4486, 2320, 2355, 4...   \n",
       "..                                                 ...   \n",
       "995  [5259, 51167, 170, 5271, 12821, 124, 767, 5527...   \n",
       "996  [67613, 37629, 2535, 77213, 3748, 1047, 1978, ...   \n",
       "997  [40408, 80057, 126, 82433, 6840, 122140, 8642,...   \n",
       "998  [97982, 16640, 17849, 2010, 17409, 1101, 2126,...   \n",
       "999  [2815, 2102, 29493, 707, 32926, 1935, 34207, 3...   \n",
       "\n",
       "                                sess_neg_sess_csid_seq  \\\n",
       "0    [146, 12, 4, 3, 34, 15, 31, 12, 74, 52, 314, 7...   \n",
       "1    [235, 37, 19, 2, 74, 152, 235, 91, 16, 2, 380,...   \n",
       "2    [3, 27, 4, 134, 72, 38, 303, 198, 110, 302, 24...   \n",
       "3    [196, 10, 196, 23, 95, 24, 230, 2, 15, 125, 10...   \n",
       "4    [186, 54, 24, 9, 33, 24, 128, 2, 57, 207, 8, 1...   \n",
       "..                                                 ...   \n",
       "995  [7, 58, 2, 27, 184, 14, 3, 83, 49, 2, 14, 22, ...   \n",
       "996  [25, 109, 2, 13, 81, 4, 2, 2, 8, 196, 20, 3, 3...   \n",
       "997  [30, 182, 2, 18, 2, 28, 16, 2, 21, 4, 103, 4, ...   \n",
       "998  [317, 369, 15, 33, 12, 39, 2, 2, 23, 235, 85, ...   \n",
       "999  [9, 2, 109, 4, 229, 5, 47, 116, 46, 2, 10, 34,...   \n",
       "\n",
       "                                sess_neg_sess_ccid_seq  \\\n",
       "0    [48, 3, 4, 131, 23, 131, 13, 3, 13, 131, 86, 1...   \n",
       "1    [131, 131, 12, 2, 13, 131, 131, 131, 131, 2, 1...   \n",
       "2    [131, 14, 4, 55, 49, 17, 131, 131, 131, 131, 9...   \n",
       "3    [131, 3, 131, 11, 53, 9, 88, 2, 131, 54, 3, 5,...   \n",
       "4    [131, 131, 9, 131, 22, 9, 65, 2, 131, 41, 8, 5...   \n",
       "..                                                 ...   \n",
       "995  [10, 131, 2, 14, 131, 131, 131, 41, 28, 2, 131...   \n",
       "996  [15, 131, 2, 131, 131, 4, 2, 2, 8, 131, 131, 1...   \n",
       "997  [7, 131, 2, 7, 2, 18, 131, 2, 16, 4, 52, 4, 7,...   \n",
       "998  [24, 131, 131, 22, 3, 25, 2, 2, 11, 131, 131, ...   \n",
       "999  [131, 2, 131, 4, 131, 5, 31, 60, 30, 2, 3, 23,...   \n",
       "\n",
       "                                 sess_neg_sess_bid_seq  \\\n",
       "0    [527, 23, 2, 84, 22, 20, 53, 461, 779, 343, 75...   \n",
       "1    [1139, 61, 160, 3, 176, 4305, 503, 1934, 4305,...   \n",
       "2    [84, 29, 2, 24, 589, 4305, 4305, 197, 4305, 43...   \n",
       "3    [121, 3, 73, 16, 531, 4305, 4305, 4, 20, 4305,...   \n",
       "4    [10, 4305, 19, 4305, 4305, 4305, 4305, 2, 17, ...   \n",
       "..                                                 ...   \n",
       "995  [19, 4305, 9, 48, 4, 44, 67, 4305, 20, 3, 8, 6...   \n",
       "996  [4305, 4305, 4, 39, 42, 268, 4, 3, 47, 4305, 2...   \n",
       "997  [4305, 4305, 2, 247, 3, 4305, 112, 4, 82, 2, 4...   \n",
       "998  [1367, 547, 65, 107, 4305, 110, 98, 4305, 11, ...   \n",
       "999  [4305, 86, 4305, 93, 2431, 21, 370, 2, 89, 68,...   \n",
       "\n",
       "                               sess_neg_sess_price_seq  \\\n",
       "0    [-1.2072219848632812, -0.9228723049163818, 0.9...   \n",
       "1    [-2.5214123725891113, 0.11688324809074402, -0....   \n",
       "2    [-0.474873423576355, -0.36009541153907776, 2.0...   \n",
       "3    [-2.759387969970703, 1.171530842781067, 1.3147...   \n",
       "4    [0.7368451356887817, -0.6964377164840698, 0.58...   \n",
       "..                                                 ...   \n",
       "995  [0.49252572655677795, 1.1661357879638672, 0.75...   \n",
       "996  [-0.43555590510368347, -1.1716824769973755, -0...   \n",
       "997  [-0.45678481459617615, -0.22726204991340637, 1...   \n",
       "998  [-1.5836411714553833, -3.095940351486206, 0.03...   \n",
       "999  [-0.21116256713867188, -0.3686261773109436, -1...   \n",
       "\n",
       "      sess_neg_sess_relative_price_to_avg_category_seq  \\\n",
       "0    [-0.8343976736068726, -0.8237003684043884, 0.0...   \n",
       "1    [-0.5392028093338013, -0.3629242181777954, -0....   \n",
       "2    [0.32676804065704346, -0.5733218789100647, 2.9...   \n",
       "3    [-0.9487777352333069, 0.9699004888534546, 8.01...   \n",
       "4    [0.5878480672836304, -0.6419907808303833, 0.20...   \n",
       "..                                                 ...   \n",
       "995  [-0.16759197413921356, 0.17139066755771637, -0...   \n",
       "996  [-0.6772119402885437, 0.016083568334579468, -0...   \n",
       "997  [0.04079359769821167, -0.2926800847053528, 0.3...   \n",
       "998  [-0.5201225876808167, -0.9587899446487427, -0....   \n",
       "999  [-0.5457116961479187, -0.7962461113929749, 0.0...   \n",
       "\n",
       "                     sess_neg_sess_product_recency_seq  \n",
       "0    [-3.5283703804016113, -3.647977113723755, -3.4...  \n",
       "1    [-3.857556104660034, -3.5666608810424805, -3.3...  \n",
       "2    [-3.857556104660034, -3.6964993476867676, -3.4...  \n",
       "3    [-3.857556104660034, -3.6995019912719727, -3.8...  \n",
       "4    [-3.4588608741760254, -3.8255484104156494, -3....  \n",
       "..                                                 ...  \n",
       "995  [-3.6690099239349365, -3.7491071224212646, -3....  \n",
       "996  [-3.857556104660034, -3.857556104660034, -3.53...  \n",
       "997  [-3.7937638759613037, -3.637340545654297, -3.5...  \n",
       "998  [-3.470968008041382, -3.3620927333831787, -3.5...  \n",
       "999  [-3.4238157272338867, -3.3644144535064697, -3....  \n",
       "\n",
       "[1000 rows x 50 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
